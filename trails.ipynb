import os 
os.chdir("../")


from langchain.document_loaders import PyPDFLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter


#Extract Data From the PDF File
def load_pdf_file(data):
    loader= DirectoryLoader(data,
                            glob="*.pdf",
                            loader_cls=PyPDFLoader)

    documents=loader.load()

    return documents

extracted_data=load_pdf_file(data='Data/')

#Split the Data into Text Chunks
def text_split(extracted_data):
    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)
    text_chunks=text_splitter.split_documents(extracted_data)
    return text_chunks

text_chunks=text_split(extracted_data)
print("Length of Text Chunks", len(text_chunks))

from langchain.embeddings import HuggingFaceEmbeddings

#Download the Embeddings from Hugging Face
def download_hugging_face_embeddings():
    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')
    return embeddings

embeddings = download_hugging_face_embeddings()

query_result = embeddings.embed_query("Hello world")
print("Length", len(query_result))

from langchain_chroma import Chroma 

texts = [doc.page_content for doc in text_chunks]
persist_directory = "./chroma_index"

vectorstore = Chroma.from_texts(texts=texts, embedding=embeddings,
                                 persist_directory=persist_directory)

# load existing vectors from persist_directory
#vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)


retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k':2})

retrieved_docs = retriever.invoke("what are allergies?")

print(retrieved_docs[0].page_content)

from langchain.prompts import PromptTemplate
from langchain.llms import CTransformers 
from langchain.chains import ConversationalRetrievalChain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.memory import ConversationBufferMemory 
from langchain_core.runnables import RunnableParallel, RunnablePassthrough,  RunnableLambda
 
# Prompt template for RAG
prompt_template = (
    "You are an assistant for question-answering tasks."
    "Use the following pieces of retrieved context to answer"
    "the question. If you don't know the answer, say that you" 
    "don't know. Use three sentences maximum and keep the answer concise"
    "\n\n" 
    "Context:\n{context}"
    "\n\n" 
    "Question:\n{question}"
)

prompt = PromptTemplate(
        input_variables=["context", "question"],
        template=prompt_template
)

# Local LLM using CTransformers (LLaMA)
llm=CTransformers(model="model/llama-2-7b-chat.ggmlv3.q4_0.bin",
                  model_type="llama",
                  config={'max_new_tokens':256,
                          'temperature':0.8})

# Memory for maintaining chat context
memory = ConversationBufferMemory(
    memory_key="chat_history", 
    return_messages=True,
    input_key="question"
)


#  Document chain
doc_chain = create_stuff_documents_chain(llm, prompt)


def get_recent_chat_history(x, k=3):
    history = memory.load_memory_variables(x)["chat_history"]
    return history[-k:] if len(history) > k else history


#  Build RAG chain with memory in LCEL 
retrieval_chain = (
    RunnableParallel({
        "context": RunnableLambda(lambda x: retriever.invoke(x["question"])),
        "question": RunnablePassthrough(),
        "chat_history": RunnableLambda(lambda x: get_recent_chat_history(x))
    }) 
    | doc_chain
)

#  Wrap in memory.save_context for chat tracking
def ask_question(user_input):
    inputs = {"question": user_input}
    response = retrieval_chain.invoke(inputs)
    memory.save_context(inputs, {"output": response})
    return response

#  Ask a question
answer = ask_question("What are allergies?")
print(answer)


answer = ask_question("how are they treated?")
print(answer)

answer = ask_question("how are they treated?")
print(answer)

answer = ask_question("how are allergies treated?")
print(answer)

answer = ask_question("severve back pain at my upper back, what is the cause and possible treatment?")
print(answer)





